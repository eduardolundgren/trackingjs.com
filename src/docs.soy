{namespace docs}

/**
 * This template will be rendered by SoyWeb when the user loads static.soy.
 * It deliberately includes dummy data so the designer can get a feel for how
 * the task list will appear with real data rather with minimal copy and paste.
 */
{template .soyweb}
{call main.page}
  {param baseDir: './' /}
  {param content}
    {call menu.side}
      {param baseDir: './' /}
    {/call}

    <div id="main">
      <div class="header">
        <h1>tracking.js</h1>
      </div>

      <div class="content">
        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit. Quos distinctio dolores eligendi illo nostrum sunt blanditiis facilis itaque, voluptatum animi laborum consequuntur! Dignissimos cumque, quod unde molestiae! Voluptatibus iusto, atque!</p>
        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit. Quos distinctio dolores eligendi illo nostrum sunt blanditiis facilis itaque, voluptatum animi laborum consequuntur! Dignissimos cumque, quod unde molestiae! Voluptatibus iusto, atque!</p>
      </div>

      <div class="header">
        <h2 id="trackers">Trackers</h2>
      </div>

      <div class="content">
        <p>In order to understand how the tracker API works, first you need to instantiate the constructor passing the targets you want to detect. Note that <code>tracking.Tracker</code> is an abstract class only used to teach how to use the API.</p>

        {literal}
        <pre><code class="javascript">var myTracker = new tracking.Tracker('target');</code></pre>
        {/literal}

        <p>
          Once you have the tracker instance, you need to know when something happens, that's why you need listen for <code>track</code> events:
        </p>
        {literal}
        <pre><code class="javascript">myTracker.on('track', function(event) {
  if (event.data.length === 0) {
    // No targets were detected in this frame.
  } else {
    event.data.forEach(function(data) {
      // Plots the detected targets here.
    });
  }
});</code></pre>
{/literal}

        <p>
          Now that you have the tracker instance listening for <code>track</code> event, you are ready to start tracking by invoking the track implementation <code>myTracker.track(pixels, width, height)</code>. This method handles all the internal logic that processes the pixels and extracts the targets from it.
        </p>

        <p>
          But don't worry, you don't need to read the <code>&lt;canvas&gt;</code>, <code>&lt;img&gt;</code> or <code>&lt;video&gt;</code> pixels manually, tracking.js provides an utility which handles that for you:
        </p>
        {literal}
        <pre><code class="javascript">var trackerTask = tracking.track('#myVideo', myTracker);</code></pre>
        {/literal}

        <p>
          It's also possible to plug the tracker instance in other elements. When tracking a <code>&lt;canvas&gt;</code> or <code>&lt;img&gt;</code>, the utility <code>tracking.track('#image', myTracker)</code> invokes only one time <code>myTracker.track(pixels, width, height)</code>. All the required arguments are fulfilled automatically, e.g. array of pixels, width and height. When using with a <code>&lt;video&gt;</code> node it is a little bit different, for each video frame the internal track implementation is executed.
        </p>

        <p>
          If you want to have full control of the tracking task you've plugged on the previous example, you may want to continue reading this section. Let's assume you need to stop the tracking from a long-running video:
        </p>

        {literal}
        <pre><code class="javascript">trackerTask.stop(); // Stops the tracking
trackerTask.run(); // Runs it again anytime
</code></pre>
{/literal}

        <p>The previous example was an abstract overview about the tracker API available. Now let's dig into some practical usages of some of the available trackers.</p>
        <p class="content-subinfo"></p>

        <h2 class="content-subhead">Color Tracker</h2>
        <p>
          Colors are everywhere in every single object. Being able to handle colored objects to control your browser through the camera is very appealing. For that reason, tracking.js implemented a basic color tracking algorithm that resulted in a real-time frame rate through a simple and intuitive API.
          It offers several significant advantages over geometric cues such as computational simplicity, robustness under partial occlusion and illumination, rotation, scale and resolution changes.
        </p>
        <p>
          In order to use a color tracker, you need to instantiate the constructor passing the colors to detect:
        </p>
        {literal}
        <pre><code class="javascript">var colors = new tracking.ColorTracker(['magenta', 'cyan', 'yellow']);</code></pre>
        {/literal}

        <p>
          Once you have the color tracker instance, you need to know when something happens, that's why you need listen for <code>track</code> events:
        </p>
        {literal}
        <pre><code class="javascript">colors.on('track', function(event) {
  if (event.data.length === 0) {
    // No colors were detected in this frame.
  } else {
    event.data.forEach(function(rect) {
      // rect.x, rect.y, rect.height, rect.width, rect.color
    });
  }
});</code></pre>
{/literal}

        <p>
          Now that you have the tracker instance listening for <code>track</code> event, you are ready to start tracking:
        </p>

        {literal}
        <pre><code class="javascript">tracking.track('#myVideo', colors);</code></pre>
        {/literal}

        <p class="content-subinfo">
          <a class="pure-button" href="http://trackingjs.com/api/" target="_blank">API docs</a>{sp}
          <a class="pure-button pure-button-primary" href="./examples/color_camera.html">Live demo &gt;</a>
        </p>

        <h2 class="content-subhead">Object Tracker</h2>
        <p>
          Having a rapid object detection as part of the library resulted in interesting examples for web applications, such as detecting faces, mouths, eyes and any other training data that could be added to the library later.
        </p>

        <p>
          In addition to the tracking.js core script, the training data for the object targets you want to track needs to be included:
        </p>

        {literal}
        <pre><code class="html">&lt;script src="tracking.js/build/data/face.js"&gt;&lt;/script&gt;
&lt;script src="tracking.js/build/data/eye.js"&gt;&lt;/script&gt;
&lt;script src="tracking.js/build/data/mouth.js"&gt;&lt;/script&gt;
</code></pre>
        {/literal}

        <p>
          In order to use object tracker, you need to instantiate the constructor passing the classifier data to detect:
        </p>
        {literal}
        <pre><code class="javascript">var objects = new tracking.ObjectTracker(['face', 'eye', 'mouth']);</code></pre>
        {/literal}

        <p>
          Once you have the object tracker instance, you need to know when something happens, that's why you need listen for <code>track</code> events:
        </p>
        {literal}
        <pre><code class="javascript">objects.on('track', function(event) {
  if (event.data.length === 0) {
    // No objects were detected in this frame.
  } else {
    event.data.forEach(function(rect) {
      // rect.x, rect.y, rect.height, rect.width
    });
  }
});</code></pre>
{/literal}

        <p>
          Now that you have the tracker instance listening for <code>track</code> event, you are ready to start tracking:
        </p>

        {literal}
        <pre><code class="javascript">tracking.track('#myVideo', objects);</code></pre>
        {/literal}

        <p class="content-subinfo">
          <a class="pure-button" href="http://trackingjs.com/api/" target="_blank">API docs</a>{sp}
          <a class="pure-button pure-button-primary" href="./examples/face_camera.html">Live demo &gt;</a>
        </p>

        <h2 class="content-subhead">Custom Tracker</h2>
        <p>
          It's easy to create your own tracker whenever you need one.
        </p>

        <p>
          Let's say for example that, for some reason, you need to build an application that finds shadows in images.  Our trackers currently don't support this use case yet, so you'll need to implement the algorithm yourself.
        </p>

        <p>
          Don't walk away yet though! You have the option of building your feature on top of tracking.js and, if you do so, you'll be able to take advantage of all the abstractions it provides, like accessing the camera and getting the pixel matrix through the canvas on every frame.
        </p>

        <p>
          It's simple! First, you just need to create a constructor for your new tracker (let's call it <code>MyTracker</code>) and have it inherit from <code>tracking.Tracker</code>:
        </p>

        {literal}
        <pre><code class="html">var MyTracker = function() {
  MyTracker(this, 'constructor');
}
tracking.inherits(MyTracker, tracking.Tracker);
</code></pre>
        {/literal}

        <p>
          Then, you need to implement the <code>track</code> method for your tracker. It will receive the pixel matrix for the current image (or video frame) and should hold the actual tracking algorithm. When the tracking is done, the code should call the <code>emit</code> method to send the results through the <code>track</code> event:
        </p>
        {literal}
        <pre><code class="javascript">var MyTracker = function() {
  MyTracker.prototype.track = function(pixels, width, height) {
    // Your code here

    this.emit('track', {
      // Your results here
    });
  }
}</code></pre>
        {/literal}

        <p>
          That's it! You can now use your tracker in the same way the other existing trackers are used. First, create an instance of it:
        </p>

        {literal}
        <pre><code class="javascript">var myTracker = new tracking.MyTracker();</code></pre>
        {/literal}

        <p>
          Then, listen to it's <code>track</code> events:
        </p>

        {literal}
        <pre><code class="javascript">myTracker.on('track', function(event) {
  // Results are inside the event
});</code></pre>
        {/literal}

        <p>
          And finally, start tracking:
        </p>

        {literal}
        <pre><code class="javascript">tracking.track('#myVideo', myTracker);</code></pre>
        {/literal}

        <p class="content-subinfo">
          <a class="pure-button" href="http://trackingjs.com/api/" target="_blank">API docs</a>{sp}
        </p>
      </div>

      <div class="header">
        <h2 id="utilities">Utilities</h2>
      </div>

      <div class="content">
        <p>
          For a better understanding of the library architecture, the implementation is divided in several utilities, it also includes several computer vision algorithms to help you implement your custom solutions.
          To develop computer vision applications using only raw JavaScript APIs could be too verbose and complex, e.g. capturing users' camera and reading its array of pixels.
        </p>

        <p>
          The big amount of steps required for a simple task makes web developers life hard when the goal is to achieve complex implementations. Some level of encapsulation is needed in order to simplify development.
          The proposed library provides encapsulation for common tasks on the web platform.
        </p>
        <p class="content-subinfo"></p>

        <h2 class="content-subhead">Feature Detection (Fast)</h2>
        <p>
          Provides an implementation of <a href="http://en.wikipedia.org/wiki/Features_from_accelerated_segment_test" target="_blank">Features from Accelerated Segment Test</a> for features detection.
          In other words it finds corners on parts of the image. Fast is faster than many other well-known feature extraction methods.
        </p>

        <p>
          To find corners, tracking.js provides the following utility:
        </p>

        {literal}
        <pre><code class="javascript">var corners = tracking.Fast.findCorners(pixels, width, height);</code></pre>
        {/literal}

        <p class="content-subinfo">
          <a class="pure-button" href="http://trackingjs.com/api/" target="_blank">API docs</a>{sp}
          <a class="pure-button pure-button-primary" href="./examples/fast.html">Live demo &gt;</a>
        </p>

        <h2 class="content-subhead">Feature Descriptor (Brief)</h2>
        <p>
          Provides an implementation of <a href="http://cvlabwww.epfl.ch/~lepetit/papers/calonder_eccv10.pdf" target="_blank">Binary Robust Independent Elementary Features</a>. It uses binary strings as an efficient feature point descriptor. As a result, Brief is very fast both to build and to match, perfect for the web.
        </p>

        <p>
          Once you have extracted image features, in our previous example the features were the image corners, you can describe each of them:
        </p>

        {literal}
        <pre><code class="javascript">var descriptors1 = tracking.Brief.getDescriptors(pixels, width, corners1);
var descriptors2 = tracking.Brief.getDescriptors(pixels, width, corners2);</code></pre>
        {/literal}

        <p>
          Brief also provides a method that you can match the features decribed in <code>descriptors1</code> and <code>descriptors2</code>:
        </p>

        {literal}
        <pre><code class="javascript">var matches = tracking.Brief.reciprocalMatch(corners1, descriptors1, corners2, descriptors2);</code></pre>
        {/literal}

        <p class="content-subinfo">
          <a class="pure-button" href="http://trackingjs.com/api/" target="_blank">API docs</a>{sp}
          <a class="pure-button pure-button-primary" href="./examples/brief_camera.html">Live demo &gt;</a>
        </p>

        <h2 class="content-subhead">Convolution</h2>
        <p>
          Convolution filters are very useful generic filters for image processing. The basic idea is that you take the weighed sum of a rectangle of pixels from the source image and use that as the output value. Convolution filters can be used for blurring, sharpening, embossing, edge detection and a whole bunch of other things.
        </p>

        <p>
          In order to horizontally convolve image pixels you can do:
        </p>

        {literal}
        <pre><code class="javascript">tracking.Image.horizontalConvolve(pixels, width, height, weightsVector, opaque);</code></pre>
        {/literal}

        <p>
          In order to vertically convolve image pixels you can do:
        </p>

        {literal}
        <pre><code class="javascript">tracking.Image.verticalConvolve(pixels, width, height, weightsVector, opaque);</code></pre>
        {/literal}

        <p>
          Or, if you need to do a separable convolve:
        </p>

        {literal}
        <pre><code class="javascript">tracking.Image.separableConvolve(pixels, width, height, horizWeights, vertWeights, opaque);</code></pre>
        {/literal}

        <p class="content-subinfo">
          <a class="pure-button" href="http://trackingjs.com/api/" target="_blank">API docs</a>{sp}
        </p>

        <h2 class="content-subhead">Gray Scale</h2>
        <p>
          Converts a color from a colorspace based on an RGB color model to a grayscale representation of its luminance.
          The coefficients represent the measured intensity perception of typical trichromat humans, in particular, human vision is most sensitive to green and least sensitive to blue.
        </p>

        <p>
          To convert the images pixels into grayscale:
        </p>

        {literal}
        <pre><code class="javascript">tracking.Image.grayscale(pixels, width, height, fillRGBA);</code></pre>
        {/literal}

        <p class="content-subinfo">
          <a class="pure-button" href="http://trackingjs.com/api/" target="_blank">API docs</a>{sp}
        </p>

        <h2 class="content-subhead">Image Blur</h2>
        <p>
          A Gaussian blur (also known as Gaussian smoothing) is the result of blurring an image by a Gaussian function. It is a widely used effect in graphics software, typically to reduce image noise and reduce detail.
          Gaussian smoothing is also used as a pre-processing stage in computer vision algorithms in order to enhance image structures at different scales.
        </p>

        <p>
          To blur the images pixels using tracking.js you can do:
        </p>

        {literal}
        <pre><code class="javascript">tracking.Image.blur(pixels, width, height, diameter);</code></pre>
        {/literal}

        <p class="content-subinfo">
          <a class="pure-button" href="http://trackingjs.com/api/" target="_blank">API docs</a>{sp}
        </p>

        <h2 class="content-subhead">Integral Image</h2>
        <p>
          A summed area table is a data structure and algorithm for quickly and efficiently generating the sum of values in a rectangular subset of a grid. In the image processing domain, it is also known as an integral image.
        </p>

        <p>
          To compute the images pixels using tracking.js you can do:
        </p>

        {literal}
        <pre><code class="javascript">tracking.Image.computeIntegralImage(
    pixels, width, height, opt_integralImage, opt_integralImageSquare,
    opt_tiltedIntegralImage, opt_integralImageSobel);</code></pre>
        {/literal}

        <p class="content-subinfo">
          <a class="pure-button" href="http://trackingjs.com/api/" target="_blank">API docs</a>{sp}
        </p>

        <h2 class="content-subhead">Sobel</h2>
        <p>
          Computes the vertical and horizontal gradients of the image and combines the computed images to find edges in the image.
          The way we implement the Sobel filter here is by first grayscaling the image, then taking the horizontal and vertical gradients and finally combining the gradient images to make up the final image.
        </p>

        <p>
          To compute the edges of the image pixels using tracking.js you can do:
        </p>

        {literal}
        <pre><code class="javascript">tracking.Image.sobel(pixels, width, height);</code></pre>
        {/literal}

        <p class="content-subinfo">
          <a class="pure-button" href="http://trackingjs.com/api/" target="_blank">API docs</a>{sp}
        </p>

        <h2 class="content-subhead">Viola Jones</h2>
        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit. Quos distinctio dolores eligendi illo nostrum sunt blanditiis facilis itaque, voluptatum animi laborum consequuntur! Dignissimos cumque, quod unde molestiae! Voluptatibus iusto, atque!</p>
      </div>

      <div class="header">
        <h2 id="web-components">Web Components</h2>
      </div>

      <div class="content">
        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit. Quos distinctio dolores eligendi illo nostrum sunt blanditiis facilis itaque, voluptatum animi laborum consequuntur! Dignissimos cumque, quod unde molestiae! Voluptatibus iusto, atque!</p>
        <p class="content-subinfo"></p>

        <h2 class="content-subhead">Color Element</h2>
        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit. Quos distinctio dolores eligendi illo nostrum sunt blanditiis facilis itaque, voluptatum animi laborum consequuntur! Dignissimos cumque, quod unde molestiae! Voluptatibus iusto, atque!</p>
        <pre><code class="html">&lt;color-tracking&gt;&lt;/color-tracking&gt;</code></pre>
        <p class="content-subinfo"></p>

        <h2 class="content-subhead">Face Element</h2>
        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit. Quos distinctio dolores eligendi illo nostrum sunt blanditiis facilis itaque, voluptatum animi laborum consequuntur! Dignissimos cumque, quod unde molestiae! Voluptatibus iusto, atque!</p>
        <pre><code class="html">&lt;face-tracking&gt;&lt;/face-tracking&gt;</code></pre>
        <p class="content-subinfo"></p>
      </div>
    </div>
  {/param}
{/call}
{/template}
